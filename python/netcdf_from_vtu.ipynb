{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions for generating NetCDF from raw VTU data using meshio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unable to revert mtime: /Library/Fonts\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import xarray as xr\n",
    "import meshio\n",
    "import gcsfs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function 1: Raw VTU to NetCDF \n",
    "\n",
    "This function accesses VTUs (unstructured grid files) stored the specified Google Cloud Storage bucket and loads them using gcsfs and meshio. The grid parameters (x_grid_cells, y_grid_cells) are properties of the model run and are user controlled. For this example, I am loading position and velocity data into the netCDF, but pressure, temperature, and age data are also available. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def vtu_transform():\n",
    "    \"\"\"\n",
    "\n",
    "    Input: \n",
    "        projname = project name \n",
    "        bucket = Google Cloud Bucket Name\n",
    "    Output:\n",
    "    datacomb - xarray dataset with dimensions (t,ynode,xnode) and coordinates (xvals, yvals),\n",
    "               Data vars - (vel_x,vel_y)\n",
    "\n",
    "    NOTE: sometimes gives warnings about Compute Engine Metadata - this does not affect loading the data \n",
    "    \"\"\"\n",
    "    projname = 'ldeo-glaciology'\n",
    "    bucket = 'ldeo-glaciology/elmer_janie/output_vals/'\n",
    "\n",
    "    fs = gcsfs.GCSFileSystem(project=projname)\n",
    "    filelist = fs.ls(bucket)\n",
    "\n",
    "\n",
    "    #info about mesh grid (set by user in model - mesh.grd file in bucket)\n",
    "    xgrid_cells = 1000\n",
    "    ygrid_cells = 30\n",
    "\n",
    "    xgrid_pts = xgrid_cells + 1\n",
    "    ygrid_pts = ygrid_cells + 1\n",
    "\n",
    "    xnodes = np.array(range(xgrid_pts)) #ynodes \n",
    "    ynodes = np.array(range(ygrid_pts))  # xnodes\n",
    "    tsteps = np.array(range(len(filelist)))  #number of time steps\n",
    "\n",
    "    timestep = [] #list of data arrays\n",
    "    for path in filelist:\n",
    "        t_val = filelist.index(path)\n",
    "        print(path)\n",
    "        #print(t_val)\n",
    "        gcs_file = fs.get(path,'out.vtu') #load file\n",
    "        mesh = meshio.read('out.vtu', file_format= 'vtu') #mesh the file\n",
    "\n",
    "        velx = mesh.point_data['velocity'][:,0].reshape((ygrid_pts,xgrid_pts)) #reshape the mesh coordinates\n",
    "        vely = mesh.point_data['velocity'][:,1].reshape((ygrid_pts,xgrid_pts))\n",
    "\n",
    "        xdim = mesh.points[:,0].reshape((ygrid_pts,xgrid_pts))\n",
    "        ydim = mesh.points[:,1].reshape((ygrid_pts,xgrid_pts))\n",
    "\n",
    "        tempdataset = xr.Dataset(data_vars = {'vel_x' : (('ynode','xnode'), velx) ,'vel_y' :(('ynode','xnode'), vely)},\n",
    "                          coords = {'yvals': (('ynode','xnode'),ydim),'xvals': (('ynode','xnode'),xdim)})\n",
    "        timestep.append(tempdataset)\n",
    "\n",
    "    datacomb = xr.concat(timestep, dim='t')\n",
    "    return datacomb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function 2: Derivatives of surface profiles \n",
    "\n",
    "Uses finite difference schemes to find first and second derivatives of the surface profiles for each time step and creates a netcdf of it. Not very long, but binder struggles with this. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def surface_deriv(datacomb):\n",
    "    \"\"\"\n",
    "\n",
    "Output:\n",
    "surfder - xarray dataset with dimensions (t,xnode) and coordinates (xvals, years), \n",
    "          Data vars - (yvals,dy,dy2)\n",
    "\n",
    "\"\"\"\n",
    "    surface = datacomb.yvals.sel(ynode = (datacomb.ynode.shape[0] - 1))\n",
    "\n",
    "    dx = (surface.xvals[0,1] - surface.xvals[0,0]).item()\n",
    "    dysurf = np.zeros(surface.shape)\n",
    "    dy2surf = np.zeros(surface.shape)\n",
    "    #calculate derivatives of profiles in each time step \n",
    "    for w in range(len(surface.t)):\n",
    "        dysurf[w,1:] = (surface.sel(t = w)[1:] - surface.sel(t = w)[0:-1])/dx\n",
    "        dy2surf[w,1:-1] = (surface.sel(t = w)[0:-2] - 2*surface.sel(t = w)[1:-1] + surface.sel(t = w)[2:])/(dx**2)\n",
    "\n",
    "    #create dataset from derivatives\n",
    "    der = xr.Dataset(data_vars = {'dy' : (('t','xnode'), dysurf), \n",
    "                                 'dy2' : (('t','xnode'), dy2surf)})\n",
    "\n",
    "    #merge derivatives dataset with surface dataset \n",
    "    surfder = xr.merge([surface.drop('yvals'),der])\n",
    "    return surfder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function 3: \n",
    "Analyzes surface profiles and their derivatives to find peaks, inflection points, and points of maximum concavity on either side of the peak. I use these points to create dataset slices of the initial data that correspond with these slices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def surf_analyze(dataset, start_idx):\n",
    "    \"\"\"\n",
    "\n",
    "    Output:\n",
    "    peak values:\n",
    "    peakdat - xarray dataset with dimensions (t,xnode,ynode) and coordinates (xvals, years), \n",
    "              Data vars - (yvals,vel_x,vel_y)\n",
    "\n",
    "\n",
    "    inflection points          \n",
    "    infldat - xarray dataset with dimensions (t,xnode,ynode) and coordinates (xvals, years), \n",
    "              Data vars - (yvals,vel_x,vel_y)\n",
    "\n",
    "    points of peak concavity\n",
    "    concdat - xarray dataset with dimensions (t,xnode,ynode) and coordinates (xvals, years), \n",
    "              Data vars - (yvals,vel_x,vel_y)\n",
    "    \"\"\"\n",
    "    T = dataset.t.shape[0]\n",
    "    \n",
    "    peakarr = []\n",
    "    inflarr = []\n",
    "    concarr = [] \n",
    "    for k in range(start_idx,dataset.t.shape[0]):\n",
    "        print(k)\n",
    "        singleslice = dataset.sel(t = k)\n",
    "        peakind = 0\n",
    "        inflind = []\n",
    "        L = singleslice.dy2.shape[0]\n",
    "\n",
    "        for i in range(L-1):\n",
    "            if singleslice.dy[i]*singleslice.dy[i+1] < 0:\n",
    "                peakind = i\n",
    "            if singleslice.dy2[i]*singleslice.dy2[i+1] < 0:\n",
    "                inflind.append(i)\n",
    "        c_l = singleslice.dy2[0:peakind].argmax()\n",
    "        c_r = singleslice.dy2[peakind:].argmax() + peakind\n",
    "\n",
    "\n",
    "        peakarr.append(datacomb.sel(t = k, xnode = peakind))\n",
    "\n",
    "        #variable number of inflection points (max 4)\n",
    "        inflset = datacomb.sel(t = k, xnode = inflind)\n",
    "        l = 4 - len(inflind)\n",
    "        #need to make the dataarray have four xnodes, even if there are less\n",
    "        if l > 0:\n",
    "            fill = xr.full_like(inflset.sel(xnode = slice(0,l)),np.nan)\n",
    "            inflsetfil = xr.concat([inflset,fill],dim = 'xnode')\n",
    "            inflarr.append(inflsetfil)\n",
    "        else:\n",
    "            inflarr.append(inflset)\n",
    "            \n",
    "    peakdat = xr.concat(peakarr, dim='t')\n",
    "    concdat = xr.concat(concarr, dim='t')\n",
    "    infldat = xr.concat(inflarr,dim='t')\n",
    "    return peakdat,concdat,infldat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
